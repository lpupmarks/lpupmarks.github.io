<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ukulele Note Detector</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            text-align: center;
            padding: 20px;
        }

        #noteDisplay {
            font-size: 2rem;
            margin-top: 20px;
        }

        #frequencyDisplay {
            font-size: 1.5rem;
            margin-top: 10px;
        }

        #consoleLog {
            margin-top: 20px;
            border: 1px solid #ccc;
            padding: 10px;
            height: 150px;
            overflow-y: scroll;
            background: #f0f0f0;
        }
    </style>
</head>
<body>
    <h1>Ukulele Note Detector</h1>
    <button id="startButton">Start Listening</button>
    <div id="noteDisplay">Note: -</div>
    <div id="frequencyDisplay">Frequency: - Hz</div>
    <div id="consoleLog">Console Log:</div>

    <script>
        const noteDisplay = document.getElementById('noteDisplay');
        const frequencyDisplay = document.getElementById('frequencyDisplay');
        const consoleLog = document.getElementById('consoleLog');
        const startButton = document.getElementById('startButton');

        let audioContext;
        let analyser;
        let pitchDetector;
        let mediaStreamSource;

        const notes = {
            'C': { frequency: 261.63 },
            'G': { frequency: 392.00 }
        };

        // Log messages to the page console
        function logMessage(message) {
            const logItem = document.createElement('div');
            logItem.textContent = message;
            consoleLog.appendChild(logItem);
            consoleLog.scrollTop = consoleLog.scrollHeight;
        }

        // Start audio processing
        async function startListening() {
            logMessage('Starting audio listening...');
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            mediaStreamSource = audioContext.createMediaStreamSource(stream);
            analyser = audioContext.createAnalyser();
            analyser.fftSize = 2048;
            mediaStreamSource.connect(analyser);
            pitchDetector = await PitchDetector.create(audioContext);
            detectPitch();
        }

        // Detect the pitch of the incoming audio
        async function detectPitch() {
            const bufferLength = analyser.fftSize;
            const buffer = new Float32Array(bufferLength);
            analyser.getFloatTimeDomainData(buffer);

            const pitch = pitchDetector.detectPitch(buffer);
            if (pitch && pitch.frequency) {
                displayNoteAndFrequency(pitch.frequency);
            }

            requestAnimationFrame(detectPitch);
        }

        // Display the detected note and frequency
        function displayNoteAndFrequency(frequency) {
            let detectedNote = '-';
            for (const [note, data] of Object.entries(notes)) {
                if (Math.abs(frequency - data.frequency) < 5) {
                    detectedNote = note;
                    break;
                }
            }

            noteDisplay.textContent = `Note: ${detectedNote}`;
            frequencyDisplay.textContent = `Frequency: ${frequency.toFixed(2)} Hz`;
            logMessage(`Detected Frequency: ${frequency.toFixed(2)} Hz, Note: ${detectedNote}`);

            if (detectedNote === 'C' || detectedNote === 'G') {
                alert('Good!');
            }
        }

        startButton.addEventListener('click', startListening);
    </script>
</body>
</html>
