<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ukulele Note Matcher</title>
    <style>
        #successDiv {
            display: none;
            padding: 20px;
            background-color: lightgreen;
            border: 2px solid green;
            margin-top: 20px;
        }
        #detectedNote {
            font-size: 20px;
            margin-top: 20px;
            color: blue;
        }
    </style>
</head>
<body>
    <h1>Ukulele Note Matcher</h1>
    <button id="startDetection">Start Detection</button>
    <div id="detectedNote">Detected Note: None</div>
    <div id="successDiv">You played the correct notes!</div>

    <script src="https://unpkg.com/pitchy/dist/pitchy.min.js"></script>
    <script>
        // Variables to manage audio processing
        let audioContext;
        let analyserNode;
        let sourceNode;
        let pitchDetector;

        // Example target notes to compare
        const targetNotes = ['C', 'E', 'G']; // Example target notes; should match your audio file notes

        // Start detection button event listener
        document.getElementById('startDetection').addEventListener('click', () => {
            startAudioProcessing();
        });

        async function startAudioProcessing() {
            // Request microphone access
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                analyserNode = audioContext.createAnalyser();
                analyserNode.fftSize = 2048;
                sourceNode = audioContext.createMediaStreamSource(stream);
                sourceNode.connect(analyserNode);

                pitchDetector = Pitchy.createDetector('wavelet', analyserNode.fftSize);

                processAudio();
            } catch (error) {
                console.error('Error accessing microphone:', error);
            }
        }

        function processAudio() {
            const buffer = new Float32Array(analyserNode.fftSize);
            const checkNotesInterval = setInterval(() => {
                analyserNode.getFloatTimeDomainData(buffer);
                const [pitch, clarity] = pitchDetector.findPitch(buffer, audioContext.sampleRate);

                if (clarity > 0.9) { // Check the clarity to ensure it is a note
                    const note = detectNoteFromFrequency(pitch);
                    if (note) {
                        // Display the detected note
                        document.getElementById('detectedNote').innerText = `Detected Note: ${note}`;

                        // Check if the detected note is in the target notes
                        if (targetNotes.includes(note)) {
                            document.getElementById('successDiv').style.display = 'block';
                            clearInterval(checkNotesInterval);
                        }
                    } else {
                        // Update if no note is detected
                        document.getElementById('detectedNote').innerText = 'Detected Note: None';
                    }
                }
            }, 200); // Interval for checking audio data
        }

        // Function to detect note from the frequency
        function detectNoteFromFrequency(frequency) {
            // Simplified example of frequency to note conversion for common ukulele notes
            if (frequency >= 261.63 && frequency <= 277.18) return 'C'; // C4
            if (frequency >= 329.63 && frequency <= 349.23) return 'E'; // E4
            if (frequency >= 392.00 && frequency <= 415.30) return 'G'; // G4
            // Extend with more notes based on the ukulele tuning and ranges
            return null;
        }
    </script>
</body>
</html>
